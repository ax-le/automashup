{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is made for experimenting purpose, in order to make new mashup technics you can add in the automashup-app/mashup.py file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim is to create new mashup technics within the /automashup-app/mashup.py file. Then, if you use the same model as the other functions, it's gonna be easy to add it in the app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of a working mashup Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells are an example of a mashup method. You may copy and paste the following example at the end of the file to make your own method. Here we assume the tracks are already separated and analyzed so you just have to run the following cell, not to modify it (unless you want to try with other songs for instance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess a song "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before applying our mashup methods, we'll be getting some data out of the song we want to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this notebook to be interesting, we suggest you to preprocess two songs first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import allin1\n",
    "import os\n",
    "from IPython.display import Audio\n",
    "\n",
    "os.chdir(\"../automashup-app/\")\n",
    "\n",
    "from utils import key_finder, increase_array_size\n",
    "from track import Track\n",
    "\n",
    "os.chdir(\"../automashup-notebook/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"\" # Path to the song\n",
    "allin1.analyze(path, out_dir='./struct', demix_dir='./separated', keep_byproducts=True, overwrite=True)\n",
    "key_finder(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the preprocessed songs as input for mashup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you preprocessed a song, it will be identified by a song name, which is the name of the file preprocessed, without the extension. For instance, for the song \"./input/song.mp3\", the track name is \"song\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your song names here\n",
    "song_name_1 = ''\n",
    "song_name_2 = ''\n",
    "# You will always have at least one track and up to four\n",
    "# If you need one track as a reference (for instance for beat structure), you will use the first one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we'll be calling a \"track\" is a python Track object with the following attributes : \n",
    "  \n",
    " \n",
    "* 'track_name' : String, \n",
    "* 'audio' : audio of the track, it's a np array it can be only a part of the song (vocals, instru, ...),\n",
    "* 'sr' : the sampling frequency, \n",
    "* 'path' : the path of the original file\n",
    "* 'bpm' : the bpm found by allin1 analysis\n",
    "* 'beats' : beats list determined by allin1 analysis\n",
    "* 'downbeats' : downbeats list determined by allin1 analysis\n",
    "* 'segments' : list of the song's phases with their phase label (verse, chorus, ...)\n",
    "* 'key' : correlation with each key (the highest value will be used as main key)\n",
    "     \n",
    "\n",
    "It's important that **your mashup methods returns the same kind of object !** Also, your method should handle up to 4 different tracks !\n",
    "Especially, metadata should look like this :\n",
    "\n",
    "{\n",
    "  \"path\": \"/home/gaubiche/Documents/MCE/Automashup/AutoMashup/mashup/input/bazard\\u00e9e.mp3\",\n",
    "  \"bpm\": 103,\n",
    "  \"beats\": [\n",
    "    4.06,\n",
    "    4.63,\n",
    "    5.23,\n",
    "    5.81,\n",
    "    ...\n",
    "  ],\n",
    "  \"downbeats\": [\n",
    "    5.23,\n",
    "    7.57,\n",
    "    9.89,\n",
    "    12.23,\n",
    "    14.56,\n",
    "    16.88,\n",
    "    19.21,\n",
    "    21.54,\n",
    "    ...\n",
    "  ],\n",
    "  \"beat_positions\": [\n",
    "    3,\n",
    "    4,\n",
    "    1,\n",
    "    2,\n",
    "    3,\n",
    "    4,\n",
    "    1,\n",
    "    ...\n",
    "  ],\n",
    "  \"segments\": [\n",
    "    {\n",
    "      \"start\": 0.0,\n",
    "      \"end\": 4.06,\n",
    "      \"label\": \"start\"\n",
    "    },\n",
    "    {\n",
    "      \"start\": 4.06,\n",
    "      \"end\": 32.59,\n",
    "      \"label\": \"verse\"\n",
    "    },\n",
    "    {\n",
    "      \"start\": 32.59,\n",
    "      \"end\": 51.21,\n",
    "      \"label\": \"chorus\"\n",
    "    },\n",
    "    ...\n",
    "  ],\n",
    "  \"key\": {\n",
    "    \"C major\": -0.512,\n",
    "    \"C# major\": 0.29,\n",
    "    ...\n",
    "  }\n",
    "}\n",
    "\n",
    "Do not freak out ! Metadatas are created within the analysis (within each track) so you won't have to set everything by hand. However, try to modify the metadatas according to the modification you do to a track to keep them consistent along the process !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's create some Track objects with our preprocessed songs\n",
    "# We'll be loading the vocals of the first song and the whole instru \n",
    "# of the second song\n",
    "\n",
    "tracks =  [] # input of the mashup methods\n",
    "\n",
    "# type attribute enables to choose a separated part of a song (from demucs source separation)\n",
    "# it can be 'vocals', 'bass', 'drums' or 'other'\n",
    "track_1 = Track.track_from_song(song_name_1, type='vocals')\n",
    "track_2 = Track.track_from_song(song_name_2, type='bass')\n",
    "track_3 = Track.track_from_song(song_name_2, type='drums')\n",
    "track_4 = Track.track_from_song(song_name_2, type='other')\n",
    "\n",
    "tracks = [track_1, track_2, track_3, track_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can have access to some attributes : \n",
    "print(f\"BPM : {track_1.bpm}\")\n",
    "print(f\"Key correlation : {track_1.key}\")\n",
    "print(f\"Beat frames : {track_1.beats}\")\n",
    "print(f\"Track audio : {track_1.audio}\")\n",
    "print(f\"Track Sampling Frequency {track_1.sr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have also some built-in functions for Track objects : \n",
    "print(f\"Key calculation (key with highest value in key correlation) : {track_1.get_key()}\")\n",
    "\n",
    "Audio(track_1.audio, rate = track_1.sr)\n",
    "\n",
    "# To repitch to another key : \n",
    "track_1.pitch_track(\"C major\")\n",
    "Audio(track_1.audio, rate = track_1.sr)\n",
    "\n",
    "Audio(track_1.audio, rate = track_1.sr)\n",
    "# To align one track phases (chorus, verse, ...) to another one's\n",
    "track_2.fit_phase(track_1)\n",
    "Audio(track_2.audio, rate = track_2.sr)\n",
    "\n",
    "# To add a metronome sound to audio\n",
    "track_1.add_metronome()\n",
    "Audio(track_1.audio, rate = track_1.sr)\n",
    "\n",
    "# lets reload our tracks from scratch to cancel our changes\n",
    "track_1 = Track.track_from_song(song_name_1, type='vocals')\n",
    "track_2 = Track.track_from_song(song_name_2, type='bass')\n",
    "\n",
    "tracks = [track_1, track_2, track_3, track_4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mashup Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../automashup-app/\") # In order to reach the file we want to load\n",
    "\n",
    "#### YOUR METHOD HERE :\n",
    "### You have to write your method in \"../automashup-app/mashup.py\"\n",
    "\n",
    "import mashup\n",
    "\n",
    "import importlib\n",
    "importlib.reload(mashup)\n",
    "\n",
    "os.chdir(\"../automashup-notebook/\") # In order to get back to our directory\n",
    "\n",
    "### Apply the method here\n",
    "\n",
    "mashup = mashup.mashup_technic(tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a listen\n",
    "Audio(mashup.audio, rate = mashup.sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "### Save the file : \n",
    "sf.write(\"mashup.wav\", mashup.audio, mashup.sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code of the mashup method is the following (you can also find it in the mashup.py file) : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mashup_technic(tracks):\n",
    "    # Mashup technic with first downbeat alignment and bpm sync\n",
    "    sr = tracks[0].sr # The first track is used to determine the target bpm\n",
    "    tempo = tracks[0].bpm\n",
    "    beginning_instant = tracks[0].downbeats[0] # downbeats metadata\n",
    "    beginning = beginning_instant * sr\n",
    "    mashup = np.zeros(0)\n",
    "    mashup_name = \"\"\n",
    "\n",
    "    # we add each track to the mashup\n",
    "    for track in tracks:\n",
    "        mashup_name += track.name + \" \" # name\n",
    "        track_tempo = track.bpm\n",
    "        track_beginning_temporal = track.downbeats[0]\n",
    "        track_sr = track.sr\n",
    "        track_beginning = track_beginning_temporal * track_sr\n",
    "        track_audio = track.audio\n",
    "\n",
    "        # reset first downbeat position\n",
    "        track_audio_no_offset = np.array(track_audio)[round(track_beginning):] \n",
    "\n",
    "        # multiply by bpm rate\n",
    "        track_audio_accelerated = librosa.effects.time_stretch(track_audio_no_offset, rate = tempo / track_tempo)\n",
    "\n",
    "        # add the right number of zeros to align with the main track\n",
    "        final_track_audio = np.concatenate((np.zeros(round(beginning)), track_audio_accelerated)) \n",
    "\n",
    "        size = max(len(mashup), len(final_track_audio))\n",
    "        mashup = np.array(mashup)\n",
    "        mashup = (increase_array_size(final_track_audio, size) + increase_array_size(mashup, size))\n",
    "\n",
    "    # we return a modified version of the first track\n",
    "    # doing so, we keep its metadata\n",
    "    tracks[0].audio = mashup\n",
    "\n",
    "    return tracks[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try to make your own !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
