{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FVArJApXWQ3N",
        "outputId": "c4eb4569-8b67-4afb-b50d-0d7d57091b61"
      },
      "outputs": [],
      "source": [
        "!apt install ffmpeg\n",
        "!pip install spleeter\n",
        "!pip install audio-separator\n",
        "!pip install museval\n",
        "!pip install protobuf==3.20.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XD6zmTTfVmAH"
      },
      "source": [
        "# Automashup : Automatic mashup generator.\n",
        "\n",
        "Automatic mashup generator algorithm. A Mashup is defined as a mix of different songs, usually formed by mixing the instrumental line of one song with the vocal line of another. In the present project we seek to implement a source separation algorithm, followed by the creation of a new song, mixing the instrumental and vocal lines of the supplied songs.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6qrxylhO8DU"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "\n",
        "from IPython.display import Audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "0PYxhXD4O8DV",
        "outputId": "16d886ae-1da5-4271-9180-c3719acd30ba"
      },
      "outputs": [],
      "source": [
        "#Load audio, the audio is sampled at 44100 Hz\n",
        "audio, sr = librosa.load('morat.mp3', sr=44100)\n",
        "Audio(data=audio, rate=sr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8o3xrA4O8DW",
        "outputId": "7a5c1f5b-e748-4a7d-b677-e0c51709ee19"
      },
      "outputs": [],
      "source": [
        "print(f\"Sampling rate: {sr}\")\n",
        "print(f\"Audio array length (duration*sr): {audio.shape[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "I-VQLMAHafZ8",
        "outputId": "d9d134a3-59e5-4268-89dd-8bf982e4d1f7"
      },
      "outputs": [],
      "source": [
        "#Visualize audio\n",
        "plt.figure(figsize=(10, 5))\n",
        "librosa.display.waveshow(audio, sr=sr)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "yfo3bF9QO8DW",
        "outputId": "a978aebe-cf7b-4d37-ea9e-39af8c429581"
      },
      "outputs": [],
      "source": [
        "#Get and visualize time-frequency domain\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "S = np.abs(librosa.stft(audio))**2\n",
        "img = librosa.display.specshow(librosa.power_to_db(S,ref=np.max), y_axis='log',sr=sr, x_axis='time', ax=ax)\n",
        "ax.set_title('Log Power Spectrogram')\n",
        "fig.colorbar(img, ax=ax, format=\"%+2.0f dB\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CnkMMqJ98rj"
      },
      "source": [
        "We can see that the audio frequencies > 11 kHz, so, we can not apply spleeter models (**Unet, Bi-LSTM**) which are trained for performing separation up to 11kHz.\n",
        "\n",
        "Spleeter released new model's version to separate audios up to 16kHz, use the same pretrain model but spectrogram estimation at separation time is then done until 16kHz. This may lead to unexpected artefacts, still we employ this model to test the performance instead of the previous one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cw3SERIyZGGZ"
      },
      "source": [
        "## Source separation algorithms\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jprr9yOHZSlT"
      },
      "source": [
        "### Spleeter method\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgDGb28JO8DX",
        "outputId": "076b7013-f192-4303-d949-38b2c8f3c7c2"
      },
      "outputs": [],
      "source": [
        "#Run source separation (mixture -> 4 stems: vocals, drums, bass, other)\n",
        "!spleeter separate -o source_separation -p spleeter:4stems-16kHz morat.mp3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "Tagu8VsVp-6X",
        "outputId": "0424ee8b-3b38-402a-e379-59f66d971f6e"
      },
      "outputs": [],
      "source": [
        "#Play estimated vocals\n",
        "Audio('source_separation/morat/vocals.wav')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rLLrZPJPqZ6v",
        "outputId": "f52c41f2-49a8-4a41-bea1-d1938ca76753"
      },
      "outputs": [],
      "source": [
        "#Play estimated drums\n",
        "Audio('source_separation/morat/drums.wav')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "93wZvxpxqZ0U",
        "outputId": "9a9aeaff-f866-4986-9419-f41f703b19db"
      },
      "outputs": [],
      "source": [
        "#Play estimated bass\n",
        "Audio('source_separation/morat/bass.wav')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "I6fhBDKeqaDI",
        "outputId": "fde1803f-b199-42ce-c422-cd57eef508a6"
      },
      "outputs": [],
      "source": [
        "#Play estimated other stem\n",
        "Audio('source_separation/morat/other.wav')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dI1iDxT5O8DX",
        "outputId": "83cf2dfa-e5ec-4f4d-c28a-fb4ea4fa2a89"
      },
      "outputs": [],
      "source": [
        "#Load and visualize ground truth and estimated stems (Waveform)\n",
        "bass, _ = librosa.load('bass.mp3', sr=44100)\n",
        "drums, _ = librosa.load('drums.mp3', sr=44100)\n",
        "vocals, _ = librosa.load('vocals.mp3', sr=44100)\n",
        "other, _ = librosa.load('other.mp3', sr=44100)\n",
        "\n",
        "bass_est, _ = librosa.load('source_separation/morat/bass.wav', sr=44100)\n",
        "drums_est, _ = librosa.load('source_separation/morat/drums.wav', sr=44100)\n",
        "vocals_est, _ = librosa.load('source_separation/morat/vocals.wav', sr=44100)\n",
        "other_est, _ = librosa.load('source_separation/morat/other.wav', sr=44100)\n",
        "\n",
        "fig, ax = plt.subplots(nrows=3, figsize=(12,10), sharex=True)\n",
        "librosa.display.waveshow(audio, sr=sr, ax=ax[0])\n",
        "ax[0].set(title='Mixture')\n",
        "ax[0].label_outer()\n",
        "\n",
        "librosa.display.waveshow(bass, sr=sr, color='r', alpha=0.6, ax=ax[1], label='bass')\n",
        "librosa.display.waveshow(other, sr=sr, color='g', alpha=0.6, ax=ax[1], label='other')\n",
        "librosa.display.waveshow(vocals, sr=sr, color='b', alpha=0.6, ax=ax[1], label='vocals')\n",
        "librosa.display.waveshow(drums, sr=sr, color='orange', alpha=0.6, ax=ax[1], label='drums')\n",
        "ax[1].set(title='Ground truth stems')\n",
        "ax[1].legend()\n",
        "ax[1].label_outer()\n",
        "\n",
        "librosa.display.waveshow(bass_est, sr=sr, color='r', alpha=0.6, ax=ax[2], label='bass_est')\n",
        "librosa.display.waveshow(other_est, sr=sr, color='g', alpha=0.6, ax=ax[2], label='other_est')\n",
        "librosa.display.waveshow(vocals_est, sr=sr, color='b', alpha=0.6, ax=ax[2], label='vocals_est')\n",
        "librosa.display.waveshow(drums_est, sr=sr, color='orange', alpha=0.6, ax=ax[2], label='drums_est')\n",
        "ax[2].set(title='Estimated stems')\n",
        "ax[2].legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "yjZkeLmYiM6f",
        "outputId": "9fa57d42-3ee2-48a2-8a52-6d1b68489821"
      },
      "outputs": [],
      "source": [
        "fft_vocals = np.fft.fft(vocals_est)\n",
        "fft_drums = np.fft.fft(drums_est)\n",
        "fft_bass = np.fft.fft(bass_est)\n",
        "fft_other = np.fft.fft(other_est)\n",
        "\n",
        "magnitude_vocals = np.abs(fft_vocals)[:int(len(fft_vocals)/2)]\n",
        "magnitude_drums = np.abs(fft_drums)[:int(len(fft_drums)/2)]\n",
        "magnitude_bass = np.abs(fft_bass)[:int(len(fft_bass)/2)]\n",
        "magnitude_other = np.abs(fft_other)[:int(len(fft_other)/2)]\n",
        "\n",
        "nyquist = sr / 2\n",
        "left_frequency = np.linspace(0, nyquist, int(len(fft_vocals)/2))\n",
        "\n",
        "max_frequency = 1000\n",
        "max_index = np.where(left_frequency > max_frequency)[0][0]\n",
        "\n",
        "# Plotting with different colors\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(left_frequency[:max_index], magnitude_vocals[:max_index], color='r', label='Vocals')\n",
        "plt.plot(left_frequency[:max_index], magnitude_drums[:max_index], color='b', label='Drums')\n",
        "plt.plot(left_frequency[:max_index], magnitude_bass[:max_index], color='g', label='Bass')\n",
        "plt.plot(left_frequency[:max_index], magnitude_other[:max_index], color='y', label='Other')\n",
        "\n",
        "plt.title('Frequency vs Magnitude (Up to 500 Hz)')\n",
        "plt.xlabel('Frequency (Hz)')\n",
        "plt.ylabel('Magnitude')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rmZrdNZkkfx9",
        "outputId": "430eeca7-1725-4964-9a20-e3f9c46f0f71"
      },
      "outputs": [],
      "source": [
        "#Visualize ground truth and estimated stems (TF domain)\n",
        "S_bass = np.abs(librosa.stft(bass))**2\n",
        "S_drums = np.abs(librosa.stft(drums))**2\n",
        "S_vocals = np.abs(librosa.stft(vocals))**2\n",
        "S_other = np.abs(librosa.stft(other))**2\n",
        "\n",
        "S_bass_est = np.abs(librosa.stft(bass_est))**2\n",
        "S_drums_est = np.abs(librosa.stft(drums_est))**2\n",
        "S_vocals_est = np.abs(librosa.stft(vocals_est))**2\n",
        "S_other_est = np.abs(librosa.stft(other_est))**2\n",
        "\n",
        "fig, ax = plt.subplots(ncols=2, nrows=4, figsize=(10,12), sharex=True)\n",
        "\n",
        "librosa.display.specshow(librosa.power_to_db(S_bass,ref=np.max), y_axis='log',sr=sr, x_axis='time', ax=ax[0,0])\n",
        "ax[0,0].set(title='Ground truth bass')\n",
        "ax[0,0].label_outer()\n",
        "librosa.display.specshow(librosa.power_to_db(S_bass_est,ref=np.max), y_axis='log',sr=sr, x_axis='time', ax=ax[0,1])\n",
        "ax[0,1].set(title='Estimated bass')\n",
        "ax[0,1].yaxis.set_label_position(\"right\")\n",
        "ax[0,1].yaxis.tick_right()\n",
        "ax[0,1].label_outer()\n",
        "\n",
        "librosa.display.specshow(librosa.power_to_db(S_drums,ref=np.max), y_axis='log',sr=sr, x_axis='time', ax=ax[1,0])\n",
        "ax[1,0].set(title='Ground truth drums')\n",
        "ax[1,0].label_outer()\n",
        "librosa.display.specshow(librosa.power_to_db(S_drums_est,ref=np.max), y_axis='log',sr=sr, x_axis='time', ax=ax[1,1])\n",
        "ax[1,1].set(title='Estimated drums')\n",
        "ax[1,1].yaxis.set_label_position(\"right\")\n",
        "ax[1,1].yaxis.tick_right()\n",
        "ax[1,1].label_outer()\n",
        "\n",
        "librosa.display.specshow(librosa.power_to_db(S_vocals,ref=np.max), y_axis='log',sr=sr, x_axis='time', ax=ax[2,0])\n",
        "ax[2,0].set(title='Ground truth vocals')\n",
        "ax[2,0].label_outer()\n",
        "librosa.display.specshow(librosa.power_to_db(S_vocals_est,ref=np.max), y_axis='log',sr=sr, x_axis='time', ax=ax[2,1])\n",
        "ax[2,1].set(title='Estimated vocals')\n",
        "ax[2,1].yaxis.set_label_position(\"right\")\n",
        "ax[2,1].yaxis.tick_right()\n",
        "ax[2,1].label_outer()\n",
        "\n",
        "librosa.display.specshow(librosa.power_to_db(S_other,ref=np.max), y_axis='log',sr=sr, x_axis='time', ax=ax[3,0])\n",
        "ax[3,0].set(title='Ground truth other stems')\n",
        "librosa.display.specshow(librosa.power_to_db(S_other_est,ref=np.max), y_axis='log',sr=sr, x_axis='time', ax=ax[3,1])\n",
        "ax[3,1].set(title='Estimated other stems')\n",
        "ax[3,1].yaxis.set_label_position(\"right\")\n",
        "ax[3,1].yaxis.tick_right()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "V3a1uTsK01mx",
        "outputId": "0580f9dd-d79f-456d-c28e-cf4fb8c44f31"
      },
      "outputs": [],
      "source": [
        "import museval\n",
        "\n",
        "src = np.concatenate([bass.reshape((1,len(bass))),\n",
        "                      drums.reshape((1,len(bass))),\n",
        "                      vocals.reshape((1,len(bass))),\n",
        "                      other.reshape((1,len(bass)))], axis=0)\n",
        "src = np.expand_dims(src, axis=2) #channels = 1\n",
        "\n",
        "estim = np.concatenate([bass_est.reshape((1,len(bass))),\n",
        "                      drums_est.reshape((1,len(bass))),\n",
        "                      vocals_est.reshape((1,len(bass))),\n",
        "                      other_est.reshape((1,len(bass)))], axis=0)\n",
        "estim = np.expand_dims(e betstim, axis=2)\n",
        "\n",
        "SDR, ISR, SIR, SAR = museval.evaluate(src, estim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Rd010hrb1g2Y"
      },
      "outputs": [],
      "source": [
        "print(f\"Bass SDR: {np.mean(SDR[0]):+.2f}, SIR: {np.mean(SIR[0]):+.2f}, SAR: {np.mean(SAR[0]):+.2f}\")\n",
        "print(f\"Drums SDR: {np.mean(SDR[1]):+.2f}, SIR: {np.mean(SIR[1]):+.2f}, SAR: {np.mean(SAR[1]):+.2f}\")\n",
        "print(f\"Vocals SDR: {np.mean(SDR[2]):+.2f}, SIR: {np.mean(SIR[2]):+.2f}, SAR: {np.mean(SAR[2]):+.2f}\")\n",
        "print(f\"Other SDR: {np.mean(SDR[3]):+.2f}, SIR: {np.mean(SIR[3]):+.2f}, SAR: {np.mean(SAR[3]):+.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nS9ovM08Rr6L"
      },
      "outputs": [],
      "source": [
        "#Residual between vocal_est and ground truth vocal\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "t = np.linspace(0,len(vocals)/44100, len(vocals))\n",
        "plt.plot(t, vocals-vocals_est)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2vPJPeheT-5"
      },
      "source": [
        "### DEMUCS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbriGE61h_S8"
      },
      "source": [
        "Demucs is a state-of-the-art music source separation model, currently capable of separating drums, bass, and vocals from the rest of the accompaniment. Demucs is based on a U-Net convolutional architecture inspired by Wave-U-Net. The v4 version features Hybrid Transformer Demucs, a hybrid spectrogram/waveform separation model using Transformers. It is based on Hybrid Demucs (also provided in this repo), with the innermost layers replaced by a cross-domain Transformer Encoder. This Transformer uses self-attention within each domain, and cross-attention across domains. The model achieves a SDR of 9.00 dB on the MUSDB HQ test set. Moreover, when using sparse attention kernels to extend its receptive field and per source fine-tuning, we achieve state-of-the-art 9.20 dB of SDR."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RJTfZDRQW4VO"
      },
      "outputs": [],
      "source": [
        "!pip install demucs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LFE0WvbnW_O6"
      },
      "outputs": [],
      "source": [
        "!python -m demucs.separate morat.mp3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "hPMMhkXiXkcO",
        "outputId": "85340d0d-2a29-48a4-ffe3-e16168ca050b"
      },
      "outputs": [],
      "source": [
        "Audio('separated/htdemucs/morat/vocals.wav')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QSGeIroiX7GR",
        "outputId": "ab996bf5-7ad7-4c27-999d-55bd97b799d9"
      },
      "outputs": [],
      "source": [
        "Audio('separated/htdemucs/morat/bass.wav')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YKiLLRB-X8sp",
        "outputId": "7889a91a-2c25-4ea1-e36d-f621d84f3d6c"
      },
      "outputs": [],
      "source": [
        "Audio('separated/htdemucs/morat/drums.wav')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ypUxRUI9X-Wx",
        "outputId": "957bb6fe-41a3-41de-f8b1-1ea8cf03aedd"
      },
      "outputs": [],
      "source": [
        "Audio('separated/htdemucs/morat/other.wav')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kWm20-WOX4ru",
        "outputId": "386bb527-1515-4b65-cd7c-359172aa5dc1"
      },
      "outputs": [],
      "source": [
        "#Load and visualize ground truth and estimated stems (Waveform)\n",
        "dm_bass, _ = librosa.load('bass.mp3', sr=44100)\n",
        "dm_drums, _ = librosa.load('drums.mp3', sr=44100)\n",
        "dm_vocals, _ = librosa.load('vocals.mp3', sr=44100)\n",
        "dm_other, _ = librosa.load('other.mp3', sr=44100)\n",
        "\n",
        "dm_bass_est, _ = librosa.load('separated/htdemucs/morat/bass.wav', sr=44100)\n",
        "dm_drums_est, _ = librosa.load('separated/htdemucs/morat/drums.wav', sr=44100)\n",
        "dm_vocals_est, _ = librosa.load('separated/htdemucs/morat/vocals.wav', sr=44100)\n",
        "dm_other_est, _ = librosa.load('separated/htdemucs/morat/other.wav', sr=44100)\n",
        "\n",
        "fig, ax = plt.subplots(nrows=3, figsize=(12,10), sharex=True)\n",
        "librosa.display.waveshow(audio, sr=sr, ax=ax[0])\n",
        "ax[0].set(title='Mixture')\n",
        "ax[0].label_outer()\n",
        "\n",
        "librosa.display.waveshow(dm_bass, sr=sr, color='r', alpha=0.6, ax=ax[1], label='bass')\n",
        "librosa.display.waveshow(dm_other, sr=sr, color='g', alpha=0.6, ax=ax[1], label='other')\n",
        "librosa.display.waveshow(dm_vocals, sr=sr, color='b', alpha=0.6, ax=ax[1], label='vocals')\n",
        "librosa.display.waveshow(dm_drums, sr=sr, color='orange', alpha=0.6, ax=ax[1], label='drums')\n",
        "ax[1].set(title='Ground truth stems')\n",
        "ax[1].legend()\n",
        "ax[1].label_outer()\n",
        "\n",
        "librosa.display.waveshow(dm_bass_est, sr=sr, color='r', alpha=0.6, ax=ax[2], label='bass_est')\n",
        "librosa.display.waveshow(dm_other_est, sr=sr, color='g', alpha=0.6, ax=ax[2], label='other_est')\n",
        "librosa.display.waveshow(dm_vocals_est, sr=sr, color='b', alpha=0.6, ax=ax[2], label='vocals_est')\n",
        "librosa.display.waveshow(dm_drums_est, sr=sr, color='orange', alpha=0.6, ax=ax[2], label='drums_est')\n",
        "ax[2].set(title='Estimated stems')\n",
        "ax[2].legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "3c7oMXSUZNS6",
        "outputId": "6de06edc-5a4b-4f39-8e38-2299688d0f91"
      },
      "outputs": [],
      "source": [
        "\n",
        "fft_vocals = np.fft.fft(dm_vocals_est)\n",
        "fft_drums = np.fft.fft(dm_drums_est)\n",
        "fft_bass = np.fft.fft(dm_bass_est)\n",
        "fft_other = np.fft.fft(dm_other_est)\n",
        "\n",
        "magnitude_vocals = np.abs(fft_vocals)[:int(len(fft_vocals)/2)]\n",
        "magnitude_drums = np.abs(fft_drums)[:int(len(fft_drums)/2)]\n",
        "magnitude_bass = np.abs(fft_bass)[:int(len(fft_bass)/2)]\n",
        "magnitude_other = np.abs(fft_other)[:int(len(fft_other)/2)]\n",
        "\n",
        "nyquist = sr / 2\n",
        "left_frequency = np.linspace(0, nyquist, int(len(fft_vocals)/2))\n",
        "\n",
        "max_frequency = 1000\n",
        "max_index = np.where(left_frequency > max_frequency)[0][0]\n",
        "\n",
        "# Plotting with different colors\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(left_frequency[:max_index], magnitude_vocals[:max_index], color='r', label='Vocals')\n",
        "plt.plot(left_frequency[:max_index], magnitude_drums[:max_index], color='b', label='Drums')\n",
        "plt.plot(left_frequency[:max_index], magnitude_bass[:max_index], color='g', label='Bass')\n",
        "plt.plot(left_frequency[:max_index], magnitude_other[:max_index], color='y', label='Other')\n",
        "\n",
        "plt.title('Frequency vs Magnitude (Up to 500 Hz)')\n",
        "plt.xlabel('Frequency (Hz)')\n",
        "plt.ylabel('Magnitude')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vcyFOWVFYRDr",
        "outputId": "1c10f050-0b50-48b1-d3a6-7db36b8e4685"
      },
      "outputs": [],
      "source": [
        "#Visualize ground truth and estimated stems (TF domain)\n",
        "S_dm_bass = np.abs(librosa.stft(dm_bass))**2\n",
        "S_dm_drums = np.abs(librosa.stft(dm_drums))**2\n",
        "S_dm_vocals = np.abs(librosa.stft(dm_vocals))**2\n",
        "S_dm_other = np.abs(librosa.stft(dm_other))**2\n",
        "\n",
        "S_dm_bass_est = np.abs(librosa.stft(dm_bass_est))**2\n",
        "S_dm_drums_est = np.abs(librosa.stft(dm_drums_est))**2\n",
        "S_dm_vocals_est = np.abs(librosa.stft(dm_vocals_est))**2\n",
        "S_dm_other_est = np.abs(librosa.stft(dm_other_est))**2\n",
        "\n",
        "fig, ax = plt.subplots(ncols=2, nrows=4, figsize=(10,12), sharex=True)\n",
        "\n",
        "librosa.display.specshow(librosa.power_to_db(S_dm_bass,ref=np.max), y_axis='log',sr=sr, x_axis='time', ax=ax[0,0])\n",
        "ax[0,0].set(title='Ground truth bass')\n",
        "ax[0,0].label_outer()\n",
        "librosa.display.specshow(librosa.power_to_db(S_dm_bass_est,ref=np.max), y_axis='log',sr=sr, x_axis='time', ax=ax[0,1])\n",
        "ax[0,1].set(title='Estimated bass')\n",
        "ax[0,1].yaxis.set_label_position(\"right\")\n",
        "ax[0,1].yaxis.tick_right()\n",
        "ax[0,1].label_outer()\n",
        "\n",
        "librosa.display.specshow(librosa.power_to_db(S_dm_drums,ref=np.max), y_axis='log',sr=sr, x_axis='time', ax=ax[1,0])\n",
        "ax[1,0].set(title='Ground truth drums')\n",
        "ax[1,0].label_outer()\n",
        "librosa.display.specshow(librosa.power_to_db(S_dm_drums_est,ref=np.max), y_axis='log',sr=sr, x_axis='time', ax=ax[1,1])\n",
        "ax[1,1].set(title='Estimated drums')\n",
        "ax[1,1].yaxis.set_label_position(\"right\")\n",
        "ax[1,1].yaxis.tick_right()\n",
        "ax[1,1].label_outer()\n",
        "\n",
        "librosa.display.specshow(librosa.power_to_db(S_dm_vocals,ref=np.max), y_axis='log',sr=sr, x_axis='time', ax=ax[2,0])\n",
        "ax[2,0].set(title='Ground truth vocals')\n",
        "ax[2,0].label_outer()\n",
        "librosa.display.specshow(librosa.power_to_db(S_dm_vocals_est,ref=np.max), y_axis='log',sr=sr, x_axis='time', ax=ax[2,1])\n",
        "ax[2,1].set(title='Estimated vocals')\n",
        "ax[2,1].yaxis.set_label_position(\"right\")\n",
        "ax[2,1].yaxis.tick_right()\n",
        "ax[2,1].label_outer()\n",
        "\n",
        "librosa.display.specshow(librosa.power_to_db(S_dm_other,ref=np.max), y_axis='log',sr=sr, x_axis='time', ax=ax[3,0])\n",
        "ax[3,0].set(title='Ground truth other stems')\n",
        "librosa.display.specshow(librosa.power_to_db(S_dm_other_est,ref=np.max), y_axis='log',sr=sr, x_axis='time', ax=ax[3,1])\n",
        "ax[3,1].set(title='Estimated other stems')\n",
        "ax[3,1].yaxis.set_label_position(\"right\")\n",
        "ax[3,1].yaxis.tick_right()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_w8YU9KeZiwx"
      },
      "source": [
        "## Evaluation of source separation methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OK4KdRmuZd90"
      },
      "outputs": [],
      "source": [
        "import museval\n",
        "\n",
        "src = np.concatenate([bass.reshape((1,len(bass))),\n",
        "                      drums.reshape((1,len(bass))),\n",
        "                      vocals.reshape((1,len(bass))),\n",
        "                      other.reshape((1,len(bass)))], axis=0)\n",
        "src = np.expand_dims(src, axis=2) #channels = 1\n",
        "\n",
        "estim = np.concatenate([dm_bass_est.reshape((1,len(bass))),\n",
        "                      dm_drums_est.reshape((1,len(bass))),\n",
        "                      dm_vocals_est.reshape((1,len(bass))),\n",
        "                      dm_other_est.reshape((1,len(bass)))], axis=0)\n",
        "estim = np.expand_dims(estim, axis=2)\n",
        "\n",
        "SDR, ISR, SIR, SAR = museval.evaluate(src, estim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pbOJ1ZytZkGF"
      },
      "outputs": [],
      "source": [
        "print(f\"Bass SDR: {np.mean(SDR[0]):+.2f}, SIR: {np.mean(SIR[0]):+.2f}, SAR: {np.mean(SAR[0]):+.2f}\")\n",
        "print(f\"Drums SDR: {np.mean(SDR[1]):+.2f}, SIR: {np.mean(SIR[1]):+.2f}, SAR: {np.mean(SAR[1]):+.2f}\")\n",
        "print(f\"Vocals SDR: {np.mean(SDR[2]):+.2f}, SIR: {np.mean(SIR[2]):+.2f}, SAR: {np.mean(SAR[2]):+.2f}\")\n",
        "print(f\"Other SDR: {np.mean(SDR[3]):+.2f}, SIR: {np.mean(SIR[3]):+.2f}, SAR: {np.mean(SAR[3]):+.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlTOEK6hecMX"
      },
      "source": [
        "### Separator model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LckeWFmbcUrz"
      },
      "outputs": [],
      "source": [
        "# Initialize the Separator with the audio file and model name\n",
        "separator = Separator('morat.mp3', model_name='UVR_MDXNET_KARA_2')\n",
        "\n",
        "# Perform the separation\n",
        "primary_stem_path, secondary_stem_path = separator.separate()\n",
        "\n",
        "print(f'Primary stem saved at {primary_stem_path}')\n",
        "print(f'Secondary stem saved at {secondary_stem_path}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tfp0ozHBgDim"
      },
      "outputs": [],
      "source": [
        "Audio('morat_(Instrumental)_UVR_MDXNET_KARA_2.wav')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CBvh3L2GgHg0"
      },
      "outputs": [],
      "source": [
        "Audio('morat_(Vocals)_UVR_MDXNET_KARA_2.wav')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "V_FzXLd6gsvl"
      },
      "outputs": [],
      "source": [
        "#Load and visualize ground truth and estimated stems (Waveform)\n",
        "vocals_, _ = librosa.load('vocals.mp3', sr=44100)\n",
        "\n",
        "vocals_est_, _ = librosa.load('morat_(Vocals)_UVR_MDXNET_KARA_2.wav', sr=44100)\n",
        "other_est_, _ = librosa.load('separated/htdemucs/morat/other.wav', sr=44100)\n",
        "\n",
        "fig, ax = plt.subplots(nrows=3, figsize=(12,10), sharex=True)\n",
        "librosa.display.waveshow(audio, sr=sr, ax=ax[0])\n",
        "ax[0].set(title='Mixture')\n",
        "ax[0].label_outer()\n",
        "\n",
        "librosa.display.waveshow(vocals_, sr=sr, color='b', alpha=0.6, ax=ax[1], label='vocals')\n",
        "ax[1].set(title='Ground truth stems')\n",
        "ax[1].legend()\n",
        "ax[1].label_outer()\n",
        "\n",
        "librosa.display.waveshow(vocals_est_, sr=sr, color='b', alpha=0.6, ax=ax[2], label='vocals_est')\n",
        "ax[2].set(title='Estimated stems')\n",
        "ax[2].legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "procom",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
