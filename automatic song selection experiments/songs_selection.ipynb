{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "import os\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file 'fma_metadata.zip' has been extracted successfully in the current directory.\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# file path to the zip file\n",
    "zip_filename = 'fma_metadata.zip'\n",
    "\n",
    "# Verify if the file exists in the current directory\n",
    "if os.path.exists(zip_filename):\n",
    "    try:\n",
    "        # Ouvrir et extraire le fichier ZIP\n",
    "        with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
    "            # Extraire tout dans le dossier actuel\n",
    "            zip_ref.extractall(os.getcwd())\n",
    "            print(f\"The file '{zip_filename}' has been extracted successfully in the current directory.\")\n",
    "    except zipfile.BadZipFile:\n",
    "        print(f\"Error: The file '{zip_filename}' is corrupted or not a zip file.\")\n",
    "else:\n",
    "    print(f\"Error: The file '{zip_filename}' does not exist in the current directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leami\\AppData\\Local\\Temp\\ipykernel_9944\\975521065.py:2: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  tracks = pd.read_csv('fma_metadata/tracks.csv', header=[1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the datasets:\n",
      "(106575, 53)\n",
      "(5489, 3)\n"
     ]
    }
   ],
   "source": [
    "#Datasets keys and tracks\n",
    "tracks = pd.read_csv('fma_metadata/tracks.csv', header=[1])\n",
    "keys = pd.read_csv('fma_metadata/keys.csv')\n",
    "#Size of the datasets\n",
    "print(\"Size of the datasets:\")\n",
    "print(tracks.shape)\n",
    "print(keys.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracks : Index(['Unnamed: 0', 'comments', 'date_created', 'date_released', 'engineer',\n",
      "       'favorites', 'id', 'information', 'listens', 'producer', 'tags',\n",
      "       'title', 'tracks', 'type', 'active_year_begin', 'active_year_end',\n",
      "       'associated_labels', 'bio', 'comments.1', 'date_created.1',\n",
      "       'favorites.1', 'id.1', 'latitude', 'location', 'longitude', 'members',\n",
      "       'name', 'related_projects', 'tags.1', 'website', 'wikipedia_page',\n",
      "       'split', 'subset', 'bit_rate', 'comments.2', 'composer',\n",
      "       'date_created.2', 'date_recorded', 'duration', 'favorites.2',\n",
      "       'genre_top', 'genres', 'genres_all', 'information.1', 'interest',\n",
      "       'language_code', 'license', 'listens.1', 'lyricist', 'number',\n",
      "       'publisher', 'tags.2', 'title.1'],\n",
      "      dtype='object')\n",
      "Index(['track_id', 'spotify_uri', 'key_and_mode'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#columns of the datasets\n",
    "print('tracks :',tracks.columns)\n",
    "print(keys.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change 'Unnamed: 0' in 'track_id'\n",
    "tracks.rename(columns={'Unnamed: 0': 'track_id'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   track_id                           spotify_uri key_and_mode\n",
      "0        10  spotify:track:66381EvBZ6e3RXzYATpGmN     F# Major\n",
      "1       141  spotify:track:7f0KQDOB9khm9ZtuWjjtre      F Major\n",
      "2       153  spotify:track:348mNhOGbcRxj7e35jASFm     C# Major\n",
      "3       173  spotify:track:1B6BPYXUp1FrxUfpRI38MM      A Major\n",
      "4       181  spotify:track:3Ddc7Lne6RjhTlRPGWpRdi      G Major\n"
     ]
    }
   ],
   "source": [
    "#print the first 5 rows of the datasets\n",
    "print(keys.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    NaN\n",
      "1    1.0\n",
      "2    1.0\n",
      "3    1.0\n",
      "4    6.0\n",
      "5    4.0\n",
      "6    4.0\n",
      "7    4.0\n",
      "8    4.0\n",
      "9    4.0\n",
      "Name: id, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#print 'id' column\n",
    "print(tracks['id'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to keep only rows where 'track_id' is numeric\n",
    "tracks = tracks[pd.to_numeric(tracks['track_id'], errors='coerce').notna()]\n",
    "\n",
    "# Convert 'track_id' to int type\n",
    "tracks['track_id'] = tracks['track_id'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   track_id  comments         date_created        date_released engineer  \\\n",
      "0        10       0.0  2008-11-26 01:45:08  2008-02-06 00:00:00      NaN   \n",
      "1       141       0.0  2008-11-26 01:49:57  2009-01-16 00:00:00      NaN   \n",
      "2       153       0.0  2008-11-26 01:50:50  2005-06-07 00:00:00      NaN   \n",
      "3       173       0.0  2008-11-26 01:51:48  2008-06-23 00:00:00      NaN   \n",
      "4       181       0.0  2008-11-26 01:52:15  2007-04-13 00:00:00      NaN   \n",
      "\n",
      "   favorites    id                                        information  \\\n",
      "0        4.0   6.0                                                NaN   \n",
      "1        1.0  60.0  <p>A full ensamble of strings, drums, electron...   \n",
      "2        0.0  69.0  <p>Self-titled debut released on Philadelphia'...   \n",
      "3        0.0  72.0  <p><em>from James' <a href=\"http://www.belowpd...   \n",
      "4        0.0  79.0  <p>This Human Ear Music reissue compiles a â€œBe...   \n",
      "\n",
      "   listens producer  ... language_code  \\\n",
      "0  47632.0      NaN  ...            en   \n",
      "1   1304.0      NaN  ...            en   \n",
      "2    628.0      NaN  ...            en   \n",
      "3    716.0      NaN  ...            en   \n",
      "4   1339.0      NaN  ...            en   \n",
      "\n",
      "                                             license  listens.1 lyricist  \\\n",
      "0  Attribution-NonCommercial-NoDerivatives (aka M...    50135.0      NaN   \n",
      "1  Attribution-Noncommercial-No Derivative Works ...      725.0      NaN   \n",
      "2  Attribution-NonCommercial-NoDerivatives (aka M...      424.0      NaN   \n",
      "3  Attribution-NonCommercial-ShareAlike 3.0 Inter...      177.0      NaN   \n",
      "4  Attribution-Noncommercial-No Derivative Works ...     1339.0      NaN   \n",
      "\n",
      "  number publisher tags.2                                           title.1  \\\n",
      "0    1.0       NaN     []                                           Freeway   \n",
      "1    4.0       NaN     []                                              Ohio   \n",
      "2    2.0       NaN     []                                Hundred-Year Flood   \n",
      "3    4.0       NaN     []  Save Life's Golden Receipt In Case Refund Needed   \n",
      "4    1.0       NaN     []                                       Gopacapulco   \n",
      "\n",
      "                            spotify_uri key_and_mode  \n",
      "0  spotify:track:66381EvBZ6e3RXzYATpGmN     F# Major  \n",
      "1  spotify:track:7f0KQDOB9khm9ZtuWjjtre      F Major  \n",
      "2  spotify:track:348mNhOGbcRxj7e35jASFm     C# Major  \n",
      "3  spotify:track:1B6BPYXUp1FrxUfpRI38MM      A Major  \n",
      "4  spotify:track:3Ddc7Lne6RjhTlRPGWpRdi      G Major  \n",
      "\n",
      "[5 rows x 55 columns]\n",
      "(5489, 55)\n",
      "['F# Major' 'F Major' 'C# Major' 'A Major' 'G Major' 'Bb Major' 'D Major'\n",
      " 'A minor' 'G# Major' 'G minor' 'D# Major' 'G# minor' 'E Major' 'C minor'\n",
      " 'C Major' 'B Major' 'F# minor' 'E minor' 'D minor' 'C# minor' 'F minor'\n",
      " 'B minor' 'D# minor' 'Bb minor']\n"
     ]
    }
   ],
   "source": [
    "# Merge the two DataFrames on 'track_id'\n",
    "df = pd.merge(tracks, keys, left_on='track_id', right_on='track_id')\n",
    "print(df.head())\n",
    "#shape\n",
    "print(df.shape)\n",
    "#songs keys\n",
    "print(df['key_and_mode'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations\n",
    "# Create a dictionary to map notes and modes to their respective semitone offsets\n",
    "semitone_offsets = {\n",
    "    'C': 0, 'C#': 1, 'Db': 1, 'D': 2, 'D#': 3, 'Eb': 3, \n",
    "    'E': 4, 'Fb': 4, 'E#': 5, 'F': 5, 'F#': 6, 'Gb': 6, \n",
    "    'G': 7, 'G#': 8, 'Ab': 8, 'A': 9, 'A#': 10, 'Bb': 10, \n",
    "    'B': 11, 'Cb': 11, 'B#': 0\n",
    "}\n",
    "# Create a dictionary to map modes to their respective values\n",
    "modes = {'Major': 0, 'minor': 1}\n",
    "\n",
    "# Transformation\n",
    "def process_key(key):\n",
    "    key = key.split(' ')\n",
    "    note = key[0]\n",
    "    mode = key[1]\n",
    "    return semitone_offsets[note], modes[mode]\n",
    "\n",
    "# Apply the transformation to the 'key_and_mode' column\n",
    "df['note'],df['mode'] = None,None\n",
    "for key in df['key_and_mode']:\n",
    "    note, mode = process_key(key)\n",
    "    df.loc[df['key_and_mode'] == key, 'note'] = note\n",
    "    df.loc[df['key_and_mode'] == key, 'mode'] = mode\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   track_id     id key_and_mode note mode\n",
      "0        10    6.0     F# Major    6    0\n",
      "1       141   60.0      F Major    5    0\n",
      "2       153   69.0     C# Major    1    0\n",
      "3       173   72.0      A Major    9    0\n",
      "4       181   79.0      G Major    7    0\n",
      "5       184   82.0     Bb Major   10    0\n",
      "6       213   86.0      D Major    2    0\n",
      "7       251  101.0      A Major    9    0\n",
      "8       331  108.0      A minor    9    1\n",
      "9       347  112.0      A minor    9    1\n"
     ]
    }
   ],
   "source": [
    "#Visualization of columns 'key_and_mode', 'note' and 'mode'\n",
    "print(df[['track_id', 'id', 'key_and_mode', 'note', 'mode']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : [10, 11, 0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "#Filter around C \n",
    "def filtre_tonalitÃ©() : \n",
    "    note_centrale = 0\n",
    "    # keep the notes in the range of -2 to 2 semitones from the central note\n",
    "    notes = [(note_centrale + i) % 12 for i in range(-2, 3)]\n",
    "    return notes\n",
    "\n",
    "#test\n",
    "print(\"1 :\",filtre_tonalitÃ©())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 11, 0, 1, 2]\n",
      "df :  [6 5 1 9 7 10 2 8 3 4 0 11]\n",
      "    track_id     id note mode\n",
      "2        153   69.0    1    0\n",
      "5        184   82.0   10    0\n",
      "6        213   86.0    2    0\n",
      "18       540  142.0    1    0\n",
      "21       547  142.0    1    0\n",
      "23       564  148.0    0    1\n",
      "25       566  148.0    0    0\n",
      "26       567  148.0   11    0\n",
      "35       608  169.0    2    1\n",
      "36       610  171.0   11    0\n",
      "(2388, 57)\n",
      "[1 10 2 0 11]\n"
     ]
    }
   ],
   "source": [
    "#Filter the DataFrame to keep only rows where 'note' is in the specified range\n",
    "notes = filtre_tonalitÃ©()\n",
    "print(notes)\n",
    "print(\"df : \",df['note'].unique())\n",
    "\n",
    "df_filtered = df[df['note'].isin(notes)]\n",
    "print(df_filtered[['track_id', 'id', 'note', 'mode']].head(10))\n",
    "print(df_filtered.shape)\n",
    "print(df_filtered['note'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    track_id     id note mode\n",
      "2        153   69.0    1    0\n",
      "5        184   82.0   10    0\n",
      "6        213   86.0    2    0\n",
      "18       540  142.0    1    0\n",
      "21       547  142.0    1    0\n",
      "25       566  148.0    0    0\n",
      "26       567  148.0   11    0\n",
      "36       610  171.0   11    0\n",
      "37       611  172.0    0    0\n",
      "39       625  177.0    0    0\n",
      "(1320, 57)\n",
      "[1 10 2 0 11]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "notes = filtre_tonalitÃ©()\n",
    "mode = 0\n",
    "# Filter the DataFrame to keep only rows where 'note' is in the specified range and mode is Major\n",
    "df_filtered = df[(df['note'].isin(notes)) & (df['mode'] == mode)]\n",
    "print(df_filtered[['track_id', 'id', 'note', 'mode']].head(10))\n",
    "print(df_filtered.shape)\n",
    "#Notes and modes in the filtered DataFrame\n",
    "print(df_filtered['note'].unique())\n",
    "print(df_filtered['mode'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rock' 'Pop' 'Folk' 'Hip-Hop' 'International' 'Blues' nan 'Experimental'\n",
      " 'Old-Time / Historic' 'Electronic' 'Country' 'Jazz' 'Classical'\n",
      " 'Instrumental' 'Soul-RnB']\n"
     ]
    }
   ],
   "source": [
    "#genres in the dataset\n",
    "print(df_filtered['genre_top'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[26]' '[27]' '[10]' '[17]' '[12]' '[21]' '[46]' '[3]' '[38, 184, 456]'\n",
      " '[1]' '[76]' '[25]' '[12, 85]' '[12, 89]' '[10, 12, 66]' '[12, 17]'\n",
      " '[10, 12]' '[30, 65]' '[25, 85]' '[8]' '[58]' '[15]' '[22, 38]'\n",
      " '[17, 103]' '[7, 10, 103]' '[12, 25, 85]' '[66]' '[17, 66, 76]'\n",
      " '[103, 137]' '[12, 66]' '[53, 66]' '[6, 7, 125]' '[12, 58, 66]' '[]'\n",
      " '[38, 79, 107]' '[10, 296]' '[297]' '[3, 17]' '[10, 103]' '[2, 8, 92]'\n",
      " '[38, 107, 224]' '[27, 38]' '[185]' '[15, 38, 42, 64]' '[4, 118, 179]'\n",
      " '[14, 21]' '[2, 103]' '[10, 89]' '[63, 137]' '[12, 103]' '[137]'\n",
      " '[26, 66]' '[12, 45, 111]' '[4]' '[58, 76]' '[53]' '[45]' '[8, 37]'\n",
      " '[17, 25]' '[12, 26]' '[33, 456]' '[66, 103]' '[33]' '[1, 138]'\n",
      " '[76, 170]' '[17, 63, 76]' '[15, 18, 26, 76]' '[17, 76, 362]'\n",
      " '[10, 27, 66]' '[9, 17, 27]' '[10, 66]' '[5, 15, 38, 46, 187]' '[27, 66]'\n",
      " '[10, 12, 66, 111]' '[38]' '[5, 456]' '[17, 33, 47, 53, 58, 66]' '[79]'\n",
      " '[15, 76]' '[26, 58, 66]' '[36, 38, 58]' '[66, 89]' '[85, 111]'\n",
      " '[26, 107, 359]' '[25, 71]' '[240, 297]' '[15, 38, 41, 297]'\n",
      " '[12, 66, 76]' '[2, 10, 17, 171]' '[1, 2, 17, 41, 103, 171, 186]'\n",
      " '[10, 85]' '[2, 10, 12, 17, 171]' '[15, 17, 27, 94]' '[9, 25, 85]'\n",
      " '[26, 38]' '[26, 66, 76]' '[17, 66]' '[66, 362]' '[42]' '[30, 38, 42]'\n",
      " '[15, 66]' '[15, 19]' '[15, 22, 42, 66]' '[15, 42, 236, 240]'\n",
      " '[42, 76, 236]' '[107, 314]' '[76, 103]' '[66, 240, 297]' '[12, 17, 103]'\n",
      " '[15, 42, 66]' '[76, 107, 184]' '[2, 8]' '[12, 32, 90]'\n",
      " '[4, 15, 542, 811]' '[10, 66, 362]' '[8, 763]' '[42, 76]' '[10, 37, 103]'\n",
      " '[15, 38, 42, 107, 184, 360]' '[15, 21, 468]' '[18, 97, 322]'\n",
      " '[18, 66, 504]' '[38, 42, 286]' '[10, 15, 27]' '[25, 27, 85]'\n",
      " '[10, 27, 85]' '[12, 137]' '[76, 98]' '[27, 66, 85, 89]'\n",
      " '[10, 16, 33, 76]' '[17, 27, 33]' '[15, 21]' '[17, 27, 103]' '[4, 74]'\n",
      " '[58, 76, 111]' '[17, 66, 76, 362]' '[12, 58, 111]' '[25, 85, 169]'\n",
      " '[94]' '[58, 89, 111]' '[66, 76, 103]' '[12, 103, 111]' '[4, 19]'\n",
      " '[17, 137]' '[240]' '[10, 15]' '[2, 45, 53]' '[36, 58, 362]'\n",
      " '[10, 27, 111]' '[12, 46]' '[4, 38, 42]' '[53, 89]' '[103]'\n",
      " '[15, 240, 297]' '[5]' '[107]' '[41, 297]' '[2, 130]' '[2, 117, 297]'\n",
      " '[10, 88]' '[12, 240]' '[25, 27, 66]' '[27, 359]' '[15, 297]'\n",
      " '[15, 21, 38]' '[15, 811]' '[12, 314]' '[66, 111]' '[66, 76]'\n",
      " '[12, 25, 111]' '[42, 107, 456]' '[25, 89, 359]' '[456, 659]'\n",
      " '[15, 38, 42, 183]' '[25, 89]' '[9, 10, 66]' '[10, 27]'\n",
      " '[27, 66, 76, 85, 89]' '[27, 514]' '[27, 53, 66]' '[15, 107, 495]'\n",
      " '[538]' '[359]' '[66, 85, 111]' '[2, 17, 103]' '[3, 10, 17]' '[49, 103]'\n",
      " '[2, 12, 38]' '[10, 12, 25]' '[10, 12, 17]' '[12, 25]' '[15, 236, 495]'\n",
      " '[15, 26, 66]' '[107, 456, 659, 1235]' '[4, 15, 26, 42, 456]' '[12, 98]'\n",
      " '[66, 103, 111]' '[89]' '[2, 12]' '[26, 359]' '[17, 25, 46]' '[10, 362]'\n",
      " '[12, 177]' '[10, 17, 137]' '[12, 27]' '[3, 12]' '[1, 32]' '[47, 107]'\n",
      " '[18, 30, 184]' '[10, 38, 296]' '[2, 17, 103, 171]' '[46, 808]' '[5, 15]'\n",
      " '[15, 468]' '[27, 76]' '[30, 32, 70]' '[10, 33]' '[2, 17, 118]'\n",
      " '[15, 76, 184, 362]' '[12, 17, 66]' '[15, 42]' '[3, 12, 17]'\n",
      " '[10, 15, 362]' '[10, 14, 19]' '[15, 27, 76]' '[10, 58, 111]'\n",
      " '[42, 47, 107]' '[18, 38, 138]' '[15, 41]' '[4, 15, 41]' '[15, 41, 58]'\n",
      " '[18]' '[25, 66]' '[286, 495]' '[5, 15, 18]' '[17, 76]' '[66, 113]'\n",
      " '[18, 184, 400]' '[10, 17, 66]' '[18, 41, 514]' '[9, 10]' '[15, 17, 38]'\n",
      " '[11]' '[15, 76, 224]' '[15, 38, 70, 183, 236]' '[12, 66, 111]'\n",
      " '[25, 111]' '[66, 94, 137]' '[30, 183, 236]' '[42, 236, 359]'\n",
      " '[49, 76, 103]' '[15, 400]' '[15, 42, 107]' '[10, 12, 38]'\n",
      " '[10, 27, 362]' '[10, 58, 85]' '[17, 66, 137]' '[130]' '[10, 15, 66]'\n",
      " '[15, 236]' '[763]' '[12, 31, 45]' '[18, 107]' '[15, 18, 322]'\n",
      " '[14, 21, 539]' '[26, 107]' '[27, 76, 359]' '[18, 33, 107]' '[4, 14, 19]'\n",
      " '[9]' '[17, 38, 107]' '[4, 15, 38]' '[236, 286, 400]' '[5, 38, 456]'\n",
      " '[10, 17]' '[4, 17, 137, 250, 322]' '[15, 18, 1235]' '[184, 456, 659]'\n",
      " '[15, 41, 1235]' '[15, 41, 76]' '[41, 46, 81]' '[41, 456, 659]'\n",
      " '[42, 107, 184]' '[41, 184, 659]' '[14, 41, 296]' '[41, 107, 659]'\n",
      " '[15, 26, 107]' '[12, 27, 76]' '[27, 58]' '[25, 53, 88]' '[42, 107]'\n",
      " '[4, 37]' '[15, 236, 337]' '[38, 1235]' '[10, 15, 267, 1235]'\n",
      " '[15, 41, 85, 88, 1235]' '[10, 32, 66, 111]' '[25, 89, 109]'\n",
      " '[10, 19, 1235]' '[15, 38, 236]' '[111]' '[42, 267]' '[267, 1235]'\n",
      " '[70, 83]' '[10, 21]' '[9, 17, 137]' '[5, 15, 38, 107, 184]'\n",
      " '[5, 107, 236, 1235]' '[100]' '[10, 17, 103]' '[1, 76, 236]'\n",
      " '[49, 94, 103]' '[27, 66, 103]' '[74, 250]' '[27, 103]' '[53, 1235]'\n",
      " '[107, 267, 1235]' '[10, 111]' '[18, 41, 1235]' '[12, 17, 25]'\n",
      " '[103, 360]' '[15, 181, 182]' '[25, 109, 169]' '[15, 42, 400]'\n",
      " '[58, 66, 85]' '[184, 400]' '[15, 42, 236]' '[15, 107, 184]' '[6, 181]'\n",
      " '[85]' '[13, 15, 42]' '[1235]' '[7, 83]' '[8, 125]' '[125]' '[15, 64]'\n",
      " '[107, 314, 659]' '[41, 66]' '[2, 15]' '[18, 42, 107, 456, 1235]'\n",
      " '[1, 107, 236]' '[17, 66, 103]' '[15, 70]' '[38, 70, 107]'\n",
      " '[15, 32, 47, 58, 250]' '[15, 38, 107]' '[21, 539]' '[15, 183, 286]'\n",
      " '[15, 17, 103]' '[15, 183, 495]' '[15, 1235]' '[15, 456, 659]'\n",
      " '[17, 27, 66]' '[15, 18, 362]' '[15, 17, 41]' '[10, 66, 76]'\n",
      " '[19, 21, 401]' '[5, 107, 236]' '[70, 183, 236]' '[3, 12, 21]'\n",
      " '[3, 10, 85]' '[15, 38]' '[58, 311, 495]' '[38, 236, 400]'\n",
      " '[182, 400, 811]' '[30, 47, 107]' '[38, 224, 286]' '[66, 77, 103]'\n",
      " '[5, 18, 107]' '[31, 32, 85]' '[1, 31]' '[17, 25, 53]' '[17, 49, 88]'\n",
      " '[15, 58, 378]' '[504]' '[17, 25, 38]' '[66, 109]' '[109]'\n",
      " '[17, 619, 1060]' '[15, 38, 70, 107, 183, 236, 495]' '[27, 32, 184]'\n",
      " '[31, 38, 107]' '[25, 26, 109]' '[18, 42, 107, 456]' '[42, 236]'\n",
      " '[10, 12, 362]' '[15, 58, 66, 495]' '[6, 21, 224]' '[314, 359]'\n",
      " '[15, 58, 66]' '[26, 98]' '[58, 359]' '[25, 63]' '[66, 359]'\n",
      " '[25, 109, 361]' '[10, 286]' '[17, 267]' '[17, 58, 98]' '[15, 296]'\n",
      " '[10, 170]' '[18, 1235]' '[3, 4, 10]' '[17, 89, 130]' '[12, 15, 36]']\n"
     ]
    }
   ],
   "source": [
    "#list of 'genres'(primary and secondary genres)\n",
    "print(df_filtered['genres'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189.0\n",
      "137.0\n",
      "243.25\n"
     ]
    }
   ],
   "source": [
    "#median and quantiles of the 'duration' column\n",
    "print(df_filtered['duration'].median())\n",
    "print(df_filtered['duration'].quantile(0.25))\n",
    "print(df_filtered['duration'].quantile(0.75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     track_id  comments         date_created        date_released    engineer  \\\n",
      "215      4929       0.0  2009-01-02 21:41:31  1999-01-03 00:00:00         NaN   \n",
      "276      7713       0.0  2009-03-13 12:25:05  2005-03-03 00:00:00        OCDJ   \n",
      "622     18584       0.0  2009-09-03 11:13:57                  NaN  kev reverb   \n",
      "726     21083       1.0  2009-11-16 12:53:26  2009-10-29 00:00:00         NaN   \n",
      "839     24736       0.0  2010-02-03 17:59:36                  NaN         NaN   \n",
      "\n",
      "     favorites      id                                        information  \\\n",
      "215        3.0  1681.0  <p>Now you will be able to hear this unique an...   \n",
      "276        1.0  2106.0  <p>Live on Trouble's show from March 3 2005 <b...   \n",
      "622        0.0  4237.0                                                NaN   \n",
      "726        4.0  4695.0  <p>From the icy depths of Canada comes â€œPample...   \n",
      "839        1.0  5412.0                                                NaN   \n",
      "\n",
      "     listens           producer  ... listens.1 lyricist  number publisher  \\\n",
      "215  62381.0                NaN  ...     492.0      NaN    17.0       NaN   \n",
      "276   5456.0            Trouble  ...     666.0      NaN     4.0       NaN   \n",
      "622    792.0  dragon or emperor  ...     113.0      NaN     0.0       NaN   \n",
      "726  12739.0                NaN  ...    1915.0      NaN     4.0       NaN   \n",
      "839   1437.0                NaN  ...     361.0      NaN     6.0       NaN   \n",
      "\n",
      "    tags.2                         title.1  \\\n",
      "215     []             4 note rising scale   \n",
      "276     []              I gave you my home   \n",
      "622     []                 Part of Me Says   \n",
      "726     []  The Boring World of Niels Bohr   \n",
      "839     []                       Ovulation   \n",
      "\n",
      "                              spotify_uri key_and_mode  note mode  \n",
      "215  spotify:track:7ssTjMFTX9DqJ9lMdim2v9      D Major     2    0  \n",
      "276  spotify:track:2aaDOaisK8wzmlKMlUk4L9     Bb Major    10    0  \n",
      "622  spotify:track:0dwhPXRsD4Oc2LIuYgp51z      D Major     2    0  \n",
      "726  spotify:track:1xKkH2ue0HtfHCkl2UuZJC      C Major     0    0  \n",
      "839  spotify:track:5UKyYZwBenb1uuSH0RvcJi      C Major     0    0  \n",
      "\n",
      "[5 rows x 57 columns]\n",
      "(75, 57)\n"
     ]
    }
   ],
   "source": [
    "# Filter the DataFrame to keep only rows where 'duration' is between -5 and 5 seconds from the median\n",
    "q1 = 184  \n",
    "q3 = 194  \n",
    "\n",
    "df_filtered = df_filtered[(df_filtered['duration'] >= q1) & (df_filtered['duration'] <= q3)]\n",
    "\n",
    "print(df_filtered.head())\n",
    "print(df_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23, 57)\n"
     ]
    }
   ],
   "source": [
    "#Remove genres : nan 'Experimental' 'Instrumental' 'Clasical' and 'Jazz'\n",
    "df_filtered = df_filtered[df_filtered['genre_top'].notna()]\n",
    "df_filtered = df_filtered[df_filtered['genre_top'] != 'Experimental']\n",
    "df_filtered = df_filtered[df_filtered['genre_top'] != 'Instrumental']\n",
    "df_filtered = df_filtered[df_filtered['genre_top'] != 'Classical']\n",
    "df_filtered = df_filtered[df_filtered['genre_top'] != 'Jazz']\n",
    "\n",
    "\n",
    "#shape\n",
    "print(df_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  7713  18584  21083  27865  29448  29472  31427  34083  52036  52276\n",
      "  53744  54298  57176  69781  72047  73768  74146  75588  85424  88861\n",
      "  90829 108031 122883]\n"
     ]
    }
   ],
   "source": [
    "#print 'id_track' unique\n",
    "print(df_filtered['track_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[17, 103]' '[45]' '[297]' '[66, 89]' '[12, 66]' '[33]' '[12, 45, 111]'\n",
      " '[12]' '[76]' '[25, 85]' '[12, 25, 111]' '[25, 89]' '[94]' '[25, 111]'\n",
      " '[17]' '[130]' '[15, 236]' '[103]' '[10]' '[66, 109]' '[8]']\n"
     ]
    }
   ],
   "source": [
    "#genres still present\n",
    "print(df_filtered['genres'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save new dataset\n",
    "df_filtered.to_csv('fma_metadata/filtered_tracks.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276      6.0\n",
      "622      4.0\n",
      "726      4.0\n",
      "911      1.0\n",
      "951      7.0\n",
      "968     14.0\n",
      "1085    13.0\n",
      "1193     4.0\n",
      "1922    13.0\n",
      "1938     6.0\n",
      "1974    11.0\n",
      "2034     1.0\n",
      "2179    18.0\n",
      "2825     1.0\n",
      "2905    14.0\n",
      "2960    20.0\n",
      "3003     8.0\n",
      "3129    12.0\n",
      "3785    10.0\n",
      "3953    25.0\n",
      "4043    21.0\n",
      "5100    18.0\n",
      "5448     5.0\n",
      "Name: tracks, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#print title of each track\n",
    "print(df_filtered['tracks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Supression of title.1 = 'Marbled Birds' and 'Futurey Gamey' (first is not present in the dataset, second is an instrumental)\n",
    "df_filtered = df_filtered[df_filtered['title.1'] != 'Marbled Birds']\n",
    "df_filtered = df_filtered[df_filtered['title.1'] != 'Futurey Gamey']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found titles: 21 sur 21\n",
      "missing titles: []\n"
     ]
    }
   ],
   "source": [
    "#Look for missing titles in the folder ./musiques\n",
    "titles = df_filtered['title.1'].astype(str).tolist()  # Convert title.1 to a list of strings\n",
    "\n",
    "# List all files in the specified folder\n",
    "folder_path = './musiques' # Replace with your folder path\n",
    "file_names = os.listdir(folder_path)\n",
    "\n",
    "# Check if the titles are present in the file names\n",
    "titles_in_files = [title for title in titles if any(title in file for file in file_names)]\n",
    "titles_missing = [title for title in titles if title not in titles_in_files]\n",
    "\n",
    "# Print the results\n",
    "print(f\"Found titles: {len(titles_in_files)} sur {len(titles)}\")\n",
    "print(\"missing titles:\", titles_missing)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
